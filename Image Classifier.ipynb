{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an open-source platform for machine learning.\n",
    "import tensorflow as tf\n",
    "# Imports specific modules (datasets, layers, and models) from TensorFlow's Keras API,\n",
    "# which is used for building and training neural networks.\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "# Imports the pyplot module from matplotlib, a popular plotting library in Python, for visualizing data and results.\n",
    "import matplotlib.pyplot as plt\n",
    "# os module, which provides a way to interact with the operating system, such as checking if a file exists.\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "# Loads the CIFAR-10 dataset, which consists of 60,000 32x32 color images in 10 different classes.\n",
    "# The dataset is split into training data (train_images and train_labels) and test data (test_images and test_labels).\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "# Normalizes the pixel values of the images by dividing them by 255.0 to scale them between 0 and 1.\n",
    "# This is important for neural network training.\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "class_names = [\n",
    "    \"airplane\",\n",
    "    \"automobile\",\n",
    "    \"bird\",\n",
    "    \"cat\",\n",
    "    \"deer\",\n",
    "    \"dog\",\n",
    "    \"frog\",\n",
    "    \"horse\",\n",
    "    \"ship\",\n",
    "    \"truck\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines the file path where the trained model will be saved or loaded from.\n",
    "# The file extension .h5 is used for saving Keras models.\n",
    "model_path = \"cifar10_cnn_model.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\MHDAH\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 26ms/step - accuracy: 0.3570 - loss: 1.7312 - val_accuracy: 0.5610 - val_loss: 1.2309\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.5858 - loss: 1.1703 - val_accuracy: 0.6436 - val_loss: 1.0074\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - accuracy: 0.6586 - loss: 0.9709 - val_accuracy: 0.6702 - val_loss: 0.9489\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.7006 - loss: 0.8514 - val_accuracy: 0.6741 - val_loss: 0.9356\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.7247 - loss: 0.7883 - val_accuracy: 0.7006 - val_loss: 0.8692\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7459 - loss: 0.7188 - val_accuracy: 0.7159 - val_loss: 0.8301\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - accuracy: 0.7665 - loss: 0.6645 - val_accuracy: 0.7114 - val_loss: 0.8412\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7835 - loss: 0.6204 - val_accuracy: 0.7136 - val_loss: 0.8425\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.7959 - loss: 0.5779 - val_accuracy: 0.7179 - val_loss: 0.8751\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.8111 - loss: 0.5333 - val_accuracy: 0.7217 - val_loss: 0.8455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk.\n"
     ]
    }
   ],
   "source": [
    "# Checks if the model file already exists at the specified path.\n",
    "if os.path.exists(model_path):\n",
    "    # Load the model if it exists\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    print(\"Model loaded from disk.\")\n",
    "else:\n",
    "    # Build and train the model if it doesn't exist\n",
    "    # Initializes a Sequential model in Keras.The model is defined as a linear stack of layers.\n",
    "    model = models.Sequential(\n",
    "        [\n",
    "            # Adds a 2D convolutional layer with 32 filters,a kernel size of (3, 3),  and ReLU activation.\n",
    "            # The first layer also specifies the input shape (32, 32, 3) for 32x32 RGB images.\n",
    "            layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "            # Adds a max-pooling layer with a pool size of (2, 2), reducing the spatial dimensions of the feature maps.\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            # Adds another 2D convolutional layer with 64 filters, a kernel size of (3, 3), and ReLU activation.\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            # Adds another max-pooling layer to reduce the dimensions further\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            # Adds another convolutional layer with 64 filters, a kernel size of (3, 3), and ReLU activation.\n",
    "            layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            # Flattens the 3D output of the convolutional layers into a 1D array to prepare it for the fully connected (dense) layers.\n",
    "            layers.Flatten(),\n",
    "            # Adds a fully connected (dense) layer with 64 units and ReLU activation.\n",
    "            layers.Dense(64, activation=\"relu\"),\n",
    "            # Adds the final output layer with 10 units (one for each class) without an activation function (since logits will be used).\n",
    "            layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        # Configures the model for training by specifying the optimizer (adam)\n",
    "        optimizer=\"adam\",\n",
    "        # loss function (SparseCategoricalCrossentropy\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        #  and evaluation metric (accuracy).\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    # Trains the model on the training data for 10 epochs while using the test data for validation.\n",
    "    \n",
    "    model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=10,\n",
    "        validation_data=(test_images, test_labels),\n",
    "    )\n",
    "\n",
    "    # Saves the trained model to disk at the specified path\n",
    "    model.save(model_path)\n",
    "    print(\"Model saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function classify_image to classify a given image using the trained model.\n",
    "def classify_image(image):\n",
    "    #Adds an extra dimension to the image array to create a batch with a single image, as TensorFlow models expect batches as input.\n",
    "    # Expands the dimensions of the image to match the input shape of the model (1, 32, 32, 3).\n",
    "    img_array = tf.expand_dims(image, 0)  # Create a batch\n",
    "    # Predicts the class probabilities for the image using the trained model.\n",
    "    predictions = model.predict(img_array)\n",
    "    # Finds the index of the class with the highest predicted probability and converts it to a NumPy integer.\n",
    "    predicted_class = tf.argmax(predictions[0]).numpy()\n",
    "    # Returns the name of the predicted class by indexing into the class_names list.\n",
    "    return class_names[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Defines a function to display an image along with its predicted class label and the true class label.\n",
    "def show_image_with_prediction(image, true_label):\n",
    "    # Gets the predicted class label for the given image.\n",
    "    predicted_label = classify_image(image)\n",
    "    # Creates a new figure for plotting.\n",
    "    plt.figure()\n",
    "    # Displays the given image.\n",
    "    plt.imshow(image)\n",
    "    # Sets the title of the plot to show the predicted and true class labels.\n",
    "    plt.title(f\"Predicted: {predicted_label}, True: {true_label}\")\n",
    "    # Hides the axis for a cleaner visualization.\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classifies the third image in the test dataset and stores the predicted label.\n",
    "class_pred = classify_image(test_images[1])\n",
    "# Calls the function to display the third test image along with its predicted class label.\n",
    "show_image_with_prediction(test_images[1], class_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
